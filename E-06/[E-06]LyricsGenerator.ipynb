{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-06]LyricsGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZAALq4bAqau/D4Fc8ZsUI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb02e277f578443f9b4cdcde2467de1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80c9536622dc4aee984b2a7f782271a7",
              "IPY_MODEL_a2c8d2942087483ca7e3c7a3d1e4e340",
              "IPY_MODEL_599109db0bdc41bbaae950af7f6aa2d4"
            ],
            "layout": "IPY_MODEL_17ebd0db5c6a4f62936d914eabd69d1e"
          }
        },
        "80c9536622dc4aee984b2a7f782271a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dc9bd6f72f74027ab6e2c8cb3ef2a35",
            "placeholder": "​",
            "style": "IPY_MODEL_e42857c0a5ed43f7b348e4dd1882585b",
            "value": "Downloading: 100%"
          }
        },
        "a2c8d2942087483ca7e3c7a3d1e4e340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0bd2d91915948c99ec748968593e954",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50f9330fdf5f456cb0316bea0fafd07c",
            "value": 2825034
          }
        },
        "599109db0bdc41bbaae950af7f6aa2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a89d325953844909a224b0ac8e050ad8",
            "placeholder": "​",
            "style": "IPY_MODEL_b976a55f41bd4868b5bbfccd3d0e1009",
            "value": " 2.69M/2.69M [00:00&lt;00:00, 8.54MB/s]"
          }
        },
        "17ebd0db5c6a4f62936d914eabd69d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc9bd6f72f74027ab6e2c8cb3ef2a35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e42857c0a5ed43f7b348e4dd1882585b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0bd2d91915948c99ec748968593e954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50f9330fdf5f456cb0316bea0fafd07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a89d325953844909a224b0ac8e050ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b976a55f41bd4868b5bbfccd3d0e1009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe1678ccb1f46259cf5696b3ea7a5ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_012aa6a655f649f2ac4489c7f7453303",
              "IPY_MODEL_32f3b6afd2384f8a914e353e9052c2bf",
              "IPY_MODEL_61c15064317141b4942448b40cd876d4"
            ],
            "layout": "IPY_MODEL_27cce30a7a2d45839d5c367f0330f6ce"
          }
        },
        "012aa6a655f649f2ac4489c7f7453303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3296807401ee4a1d9b235b691b2c5ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_be2e319749d946a78537022987a822af",
            "value": "Downloading: 100%"
          }
        },
        "32f3b6afd2384f8a914e353e9052c2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a29ffa1c3b74215b18e55b353b22cfc",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eab8d1df3fb643ea9f8918240e62cba3",
            "value": 1000
          }
        },
        "61c15064317141b4942448b40cd876d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89aac0e1749143f99d6c697c05c6ce77",
            "placeholder": "​",
            "style": "IPY_MODEL_fe4434d9ae614438a2399a9656dfafb0",
            "value": " 0.98k/0.98k [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "27cce30a7a2d45839d5c367f0330f6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3296807401ee4a1d9b235b691b2c5ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2e319749d946a78537022987a822af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a29ffa1c3b74215b18e55b353b22cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eab8d1df3fb643ea9f8918240e62cba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89aac0e1749143f99d6c697c05c6ce77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4434d9ae614438a2399a9656dfafb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [E-06] AI로 작사를 한다는 것\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "< 목 차 >\n",
        "\n",
        "###I.   서 론\n",
        "\n",
        "###II.  본 론\n",
        "\n",
        "1. **문장 생성; validation loss 평가**  \n",
        "\n",
        "    1) Baseline 구축  \n",
        "    2) Hyper parameter 조정  \n",
        "    3) Vocabulary 확대\n",
        "\n",
        "2. **시적표현 선별; 정성적 평가**  \n",
        "3. **Case study**  \n",
        "\n",
        "\n",
        "\n",
        "###III. 결 론\n",
        "\n",
        "<br><br><br>\n",
        "\n"
      ],
      "metadata": {
        "id": "leVYjy_xVvHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **I.  서 론**\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "####**[ 배경 및 의의 ]**\n",
        "\n",
        "**작사**(作詞), 노랫말을 만드는 것. \n",
        "\n",
        "이번 과정에서는 Deep learning 중에서도 **순환신경망(RNN)**을 활용하여 작사를 하는 인공지능을 구현해 본다. 노랫말에는 감정과 생각이 넘치게 담겨있거나 극도로 절제되어 있다. 시적허용이 빈번한 언어표현 중 하나이기도 하다. 그저 '문장 생성'이 아니라 '작사'라면 단순히 어법에 맞는 문장을 만들어내는 그 이상이 되어야 할 것이다. 특히 노래가사가 갖는 함축적이고 은유적인 특성을 담아낼 수 있어야 한다. 그게 가능할까.\n",
        "\n",
        "진심을 담은 글은 사람의 마음도 움직이게 할 수 있다고 믿으며 살았다. 기계가 만들어낸 문장이 사람의 마음을 움직일 수 있을지, 그리고 그런 작업을 내 손으로 해낼 수 있을지. 기대가 되면서도 또 한편으론 묘한 감정으로 Exploration을 시작한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "####**[ 목표 ]**\n",
        "*   자연어 전처리 과정의 이해\n",
        "*   RNN(Recurrent Neural Network)을 활용한 MODEL 구현\n",
        "*   뜻이 통하는 문장의 생성\n",
        "*   노랫말로서의 평가 및 함의 도출\n",
        "*   성능향상을 위한 방안 고찰\n",
        "\n",
        "\n",
        "<br><br><br>\n"
      ],
      "metadata": {
        "id": "0cBbyPWRSO06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **II. 본 론**"
      ],
      "metadata": {
        "id": "S8GdvnPWSxWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에 구현할 RNN(Recurrent Neural Network) MODEL에서 조정할 수 있는 주요 인자 가운데 Embedding size, Hidden size, Batch size가 있다. 각각의 개념과 함께 함의를 생각봄으로써 어떤 방식으로 이를 조정해나갈 것인지 방향을 설정할 수 있을 것이다. \n",
        "\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "**[개념 정리]**\n",
        "\n",
        "\n",
        "**⎮ Embedding size**\n",
        "\n",
        "Embedding 이란 가중치 매개변수로부터 단어에 해당하는 행(벡터)를 추출하는 계층이다. 이 Embedding 계층에 단어의 임베딩(분산 표현)이 저장된다. \n",
        "\n",
        "Embedding size는 워드 벡터의 차원수, 즉 단어가 추상적으로 표현되는 크기다. 값이 커질수록 단어의 추상적인 특징을 더 잡아낼 수 있지만 그만큼 충분한 데이터가 주어지지 않으면 오히려 혼란을 야기한다.[1]\n",
        "\n",
        "<br>\n",
        "\n",
        "**⎮ Hidden size**\n",
        "\n",
        "RNN 계층의 순환구조 내에는 '닫힌 경로' 또는 '순환하는 경로'가 존재한다. 여기서 데이터가 순환하면서 정보가 끊임없이 갱신되는 것이다. 이로 인해 과거의 정보를 기억하는 동시에 최신 데이터로 갱신할 수 있다.[3] \n",
        "\n",
        "LMS 본문에서는 Hidden state의 차원수에 해당하는 Hidden size를 '모델에 얼마나 많은 일꾼을 둘 것인가'로 이해할 수 있다고 설명한다. 그 일꾼들이 모두 같은 데이터를 보고 각자의 생각을 가지는데, 충분한 데이터가 주어지면 올바른 결정을 내리겠지만 그렇지 않으면 역효과다. \n",
        "\n",
        "<br>\n",
        "\n",
        "**⎮ Batch size**\n",
        "\n",
        "Batch는 하나로 묶은 데이터를 한꺼번에 입력하여 처리하는 방식을 의미한다. Batch를 적용하여 개개의 데이터를 다룰 때보다 큰 배열의 정보를 효율적으로 처리할 수 있고 부하를 줄일 수 있다. 또한 데이터 학습 시 Batch 단위로 대표성을 지닌 가중치를 업데이트 함으로써 Model의 범용성을 높일 수 있다.\n",
        "\n",
        "이때 어느 정도의 데이터를 한 묶음으로 나타낼 것인지가 Batch size다. 일반적으로 Batch size가 너무 클 경우 한 번에 처리해야 할 데이터가 많아지므로 메모리 부족문제가 발생할 수 있고, 너무 작을 경우에는 가중치 업데이트의 표본으로 역할이 어려울 수 있다.  "
      ],
      "metadata": {
        "id": "GdQgnUmzn8Uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br>\n",
        "\n",
        "\n",
        "##**1. 문장 생성**; validation loss 평가\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aKGjl_wKXs-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "###**1) Data 처리 및 Baseline 구축**\n",
        "\n",
        "<br>\n",
        "\n"
      ],
      "metadata": {
        "id": "ZsWosgCFLBvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXI8vx0zvBr5",
        "outputId": "79183ffe-d272-48e5-904d-264a58221577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "''' 구글드라이브 마운트 '''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPBlrza1rBDD"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55gWlJuysQaF",
        "outputId": "8620e165-805e-48a9-b550-4febba7d5115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " [\"Let's stay together I, I'm I'm so in love with you\", 'Whatever you want to do', 'Is all right with me']\n"
          ]
        }
      ],
      "source": [
        "txt_file_path = '/content/drive/MyDrive/data/LSMdata/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDxpL8oEwofQ"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "**[ 데이터 정제 ]**\n",
        "\n",
        "preprocess_sentence() 함수를 활용하여 데이터를 정제한다. 이때 지나치게 긴 문장은 과도한 Padding의 원인이 될 수 있어서 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하였다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVCK73oesYPg",
        "outputId": "0da3196a-a785-4e1c-c764-85785683786a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ],
      "source": [
        "import os, re \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
        "    sentence = sentence.strip() # 5\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
        "    return sentence\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwWvWevnxwEp",
        "outputId": "273e5fc7-12f1-498a-c32e-5810c872082d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> whatever you want to do <end>',\n",
              " '<start> is all right with me <end>',\n",
              " '<start> cause you make me feel so brand new <end>',\n",
              " '<start> loving you forever <end>',\n",
              " '<start> is what i need <end>',\n",
              " '<start> let me , be the one you come running to <end>',\n",
              " '<start> i ll never be untrue oh baby <end>',\n",
              " '<start> let s , let s stay together gether <end>',\n",
              " '<start> lovin you whether , whether <end>',\n",
              " '<start> times are good or bad , happy or sad <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# 정제된 문장 수집\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # 삭제\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 정제\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    if len(preprocessed_sentence.split()) > 15: continue   # 토큰 생성 시 15개 이상 제외\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "corpus[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "W69poq75bWkn",
        "outputId": "acb75165-0c37-4998-81de-d1e8b6abb36c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> whatever you want to do <end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "corpus[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvkW32rU0tUu"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "**[ 토큰 생성 ]**\n",
        "\n",
        "\n",
        "TensorFlow의 Tokenizer와 pad_sequences를 사용하였다. \n",
        "\n",
        "12000단어를 기억할 수 있는 tokenizer를 생성하고, corpus를 이용해 tokenizer 내부의 단어장을 완성한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJI31QMg0YEe",
        "outputId": "c521c4ff-515c-4aa4-fb0c-a8af41389ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2 570   7 ...   0   0   0]\n",
            " [  2  26  25 ...   0   0   0]\n",
            " [  2  66   7 ...   0   0   0]\n",
            " ...\n",
            " [  2  21  77 ...   0   0   0]\n",
            " [  2  41  26 ...   0   0   0]\n",
            " [  2  21  77 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7ff24e16e3d0>\n"
          ]
        }
      ],
      "source": [
        "def tokenize(corpus):\n",
        "    # tokenizer\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    # corpus를 이용, tokenizer 내부의 단어장을 완성\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # corpus를 Tensor로 변환\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwu3f-v1bd06",
        "outputId": "9bb44ae4-fc02-4059-adb0-db0fbf1504b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2 570   7 ...   0   0   0]\n",
            " [  2  26  25 ...   0   0   0]\n",
            " [  2  66   7 ...   0   0   0]\n",
            " ...\n",
            " [  2  21  77 ...   0   0   0]\n",
            " [  2  41  26 ...   0   0   0]\n",
            " [  2  21  77 ...   0   0   0]]\n",
            "<keras_preprocessing.text.Tokenizer object at 0x7ff24e16e3d0>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.text.Tokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(tensor)\n",
        "print(tokenizer)\n",
        "type(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSNHbQHB0--7",
        "outputId": "027a8164-55d8-4b19-880e-1b742b6a4d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : i\n",
            "5 : ,\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ],
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRxK3cIB1TaB",
        "outputId": "0b38fa29-f9f9-415a-d4b1-8f4c63a56a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2 570   7  64  10  48   3   0   0   0   0   0   0   0]\n",
            "[570   7  64  10  48   3   0   0   0   0   0   0   0   0]\n"
          ]
        }
      ],
      "source": [
        "# source 문장 생성\n",
        "src_input = tensor[:, :-1]  \n",
        "\n",
        "# target 문장 생성\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsDcyOpSf9zu",
        "outputId": "589873c4-23cd-4922-ef9e-d5a9b46a2647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(124810, 14)\n",
            "(124810, 14)\n",
            "(31203, 14)\n",
            "(31203, 14)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                          tgt_input,\n",
        "                                                          test_size=0.2,\n",
        "                                                          shuffle=True, \n",
        "                                                          random_state=42)\n",
        "\n",
        "print(enc_train.shape)\n",
        "print(dec_train.shape)\n",
        "print(enc_val.shape)\n",
        "print(dec_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TsvddrH3-yy"
      },
      "source": [
        "이제, 데이터셋 객체를 생성한다. tf.data.Dataset객체를 생성하는 방법을 사용하고, 이 경우 데이터 입력 파이프라인을 통한 속도 개선 및 각종 편의 기능을 제공이 가능하다고 한다.\n",
        "\n",
        "data.Dataset.from_tensor_slices() 메소드를 이용해 tf.data.Dataset객체를 생성하였다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asf1WyyE39CY",
        "outputId": "f2605962-5969-4491-efff-a6bd7400fbd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 14), dtype=tf.int32, name=None), TensorSpec(shape=(256, 14), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "BUFFER_SIZE = len(enc_train)\n",
        "VAL_BUFFER_SIZE = len(enc_val)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 + 0:<pad>를 포함\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_dataset = val_dataset.shuffle(VAL_BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset\n",
        "val_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayhNcdqE5u3k"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "**[ Model Baseline ]**\n",
        "\n",
        "Model Baseline을 구축한다. tf.keras.Model을 Subclassing하는 방식으로 1개의 Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성한다.\n",
        "\n",
        "앞서 설명한 MODEL 주요인자(Embedding size, Hidden size)의 초기값은 LSM 본문에서 제시한 수치를 적용하였다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-H-Vj-R54h1"
      },
      "outputs": [],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsXgs1VY7mNd",
        "outputId": "148250ae-a020-46d3-ae8e-6c95e5409956"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [-1.14914175e-04,  1.22720903e-05, -1.35023529e-05, ...,\n",
              "          1.31604756e-04,  1.34788919e-04,  2.11093196e-04],\n",
              "        [-2.55467487e-04,  4.14302689e-04, -3.21768021e-04, ...,\n",
              "          5.45756775e-05,  9.59930694e-05,  2.55789229e-04],\n",
              "        ...,\n",
              "        [ 4.15577961e-04, -1.41334464e-03, -1.75792069e-04, ...,\n",
              "         -1.73327129e-03, -1.50814676e-03, -1.33213529e-03],\n",
              "        [ 4.65762976e-04, -1.45521958e-03, -2.33292812e-04, ...,\n",
              "         -2.11211061e-03, -1.78880326e-03, -1.56622974e-03],\n",
              "        [ 5.33356040e-04, -1.42603402e-03, -3.00203945e-04, ...,\n",
              "         -2.42884853e-03, -2.05076626e-03, -1.75904576e-03]],\n",
              "\n",
              "       [[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [-3.54821350e-05,  4.58741561e-05,  6.86888452e-05, ...,\n",
              "          5.34385268e-04,  4.07935586e-04, -6.37207413e-05],\n",
              "        [-3.90492060e-05,  6.04281704e-05, -1.41435259e-04, ...,\n",
              "          7.05976621e-04,  5.83518296e-04, -2.02500334e-04],\n",
              "        ...,\n",
              "        [ 1.17286225e-03,  1.21573121e-05,  1.48144318e-03, ...,\n",
              "          1.00631314e-05,  4.80063754e-05,  1.13354414e-03],\n",
              "        [ 1.06872816e-03,  1.24837723e-04,  1.12968427e-03, ...,\n",
              "          1.69801846e-04,  1.53506437e-04,  1.09122694e-03],\n",
              "        [ 1.39560155e-03, -1.37001218e-04,  8.72932433e-04, ...,\n",
              "          6.34197087e-04,  3.75267497e-04,  1.10098033e-03]],\n",
              "\n",
              "       [[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [ 9.83882273e-05, -3.06285539e-04,  1.19232682e-04, ...,\n",
              "          4.45610174e-04,  3.80935613e-04,  2.87461124e-04],\n",
              "        [ 2.14439904e-04, -3.59080586e-04,  2.11439445e-04, ...,\n",
              "          6.50769158e-04,  4.51386673e-04,  1.41197655e-04],\n",
              "        ...,\n",
              "        [ 6.15732861e-05, -5.03862859e-04, -8.90809752e-04, ...,\n",
              "         -4.62360447e-04, -6.47352135e-04,  1.36529939e-04],\n",
              "        [ 7.27245642e-05, -7.29785301e-04, -8.92500684e-04, ...,\n",
              "         -1.09669799e-03, -9.55847383e-04, -2.49924517e-04],\n",
              "        [ 1.02418562e-04, -9.06052941e-04, -8.74135469e-04, ...,\n",
              "         -1.67692255e-03, -1.26890396e-03, -6.05864450e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [ 4.31930384e-05, -1.61593285e-04,  2.75526894e-04, ...,\n",
              "          2.02420604e-04,  1.32154033e-04,  1.26646773e-04],\n",
              "        [-6.01465501e-07, -3.78207566e-04,  3.37540812e-04, ...,\n",
              "          1.85284473e-04, -5.43463611e-05,  2.30241087e-04],\n",
              "        ...,\n",
              "        [ 1.92205247e-04, -1.06452336e-03, -3.43240361e-04, ...,\n",
              "         -2.53887940e-03, -2.14704638e-03, -1.53729750e-03],\n",
              "        [ 3.29963746e-04, -1.01427222e-03, -4.29589389e-04, ...,\n",
              "         -2.77755246e-03, -2.32591433e-03, -1.68971438e-03],\n",
              "        [ 4.73675871e-04, -9.32581373e-04, -5.16506261e-04, ...,\n",
              "         -2.96830339e-03, -2.49841437e-03, -1.82037032e-03]],\n",
              "\n",
              "       [[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [-1.25287639e-04, -7.00176533e-05, -1.66240847e-04, ...,\n",
              "          3.68700013e-04,  3.85985622e-04, -1.68372244e-05],\n",
              "        [-5.32822974e-04, -7.37209048e-05, -3.37352831e-04, ...,\n",
              "          2.47256481e-04,  7.46399164e-05, -3.00280575e-04],\n",
              "        ...,\n",
              "        [-2.25644253e-04, -1.61546667e-03, -7.26264916e-05, ...,\n",
              "         -1.60568825e-03, -1.07534556e-03, -1.62407476e-03],\n",
              "        [-9.34730269e-05, -1.62408652e-03, -7.40221294e-05, ...,\n",
              "         -2.04723189e-03, -1.36155530e-03, -1.84004288e-03],\n",
              "        [ 3.73297080e-05, -1.57048716e-03, -1.00578603e-04, ...,\n",
              "         -2.41383002e-03, -1.64381287e-03, -2.01786379e-03]],\n",
              "\n",
              "       [[-2.99471649e-05, -1.44973428e-05,  3.18330385e-05, ...,\n",
              "          3.14648350e-04,  2.06530021e-04,  8.14726664e-05],\n",
              "        [ 4.53366752e-04, -1.73932072e-04, -1.30813452e-04, ...,\n",
              "          2.75888597e-04,  3.00244690e-04,  1.83698372e-04],\n",
              "        [ 9.84357670e-04, -3.98924632e-04, -5.20903959e-05, ...,\n",
              "          2.23507523e-04,  2.51201942e-04,  1.66424987e-04],\n",
              "        ...,\n",
              "        [ 9.96893272e-04, -5.20787493e-04, -4.00235731e-04, ...,\n",
              "         -1.05917430e-03, -8.53040430e-04, -1.03155209e-03],\n",
              "        [ 9.71777714e-04, -6.63081766e-04, -4.25997336e-04, ...,\n",
              "         -1.58777810e-03, -1.20136491e-03, -1.23527262e-03],\n",
              "        [ 9.67485947e-04, -7.48934399e-04, -4.54596826e-04, ...,\n",
              "         -2.02885224e-03, -1.52729359e-03, -1.42008346e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러와서 모델에 넣기 \n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "model(src_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "Embedding 레이어, 2개의 LSTM 레이어, Dense 레이어로 구성된 Model 형태를 확인할 수 있다."
      ],
      "metadata": {
        "id": "5P-QXoFBf67-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__iPaV_iAFm8",
        "outputId": "e2c69e42-2851-45f6-83cb-5a1ebf8a85d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  3072256   \n",
            "                                                                 \n",
            " lstm (LSTM)                 multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               multiple                  8392704   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  12301025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "**[ Model fitting ]**\n",
        "\n",
        "<br>\n",
        "\n",
        "Model fitting 시, epoch가 일정 수준 이상이 되었을 때 과적합이 발생하는 것을 방지하고자 Callback을 적용하였다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**⎮ CALLBACK**\n",
        "\n",
        "Callback은 훈련과정 중간에 어떤 작업을 수행할 수 있게 하는 객체로, Keras에서 제공하는 클래스다. fit() method의 callbacks매개변수에 리스트로 전달하여 사용한다.[2]\n",
        "\n",
        "**ModelCheckpoint**로 가장 낮은 손실값의 모델을 자동으로 저장해주고, **EarlyStopping**으로 손실값이 낮아지지 않으면 학습을 중지하도록 설정(patience=1)했다. ModelCheckpoint와 EarlySttopping을 함께 사용하면 과적합이 되지 않도록 조정하여 최상의 모델을 찾는 데 용이하며, 컴퓨터 자원 및 시간을 아낄 수 있다.\n",
        "\n",
        "안전장치를 걸어두었으니 epoch 값은 300으로 설정하고, 학습을 시작한다."
      ],
      "metadata": {
        "id": "8plfpiK4fTQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "EPOCH = 300\n",
        "\n",
        "# ModelCheckpoint\n",
        "filename = 'best_epoch{}_batch{}.h5'.format(EPOCH, BATCH_SIZE)\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filename,\n",
        "                                                   monitor='val_loss',\n",
        "                                                   verbose=1,\n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_best_only=True,\n",
        "                                                   mode='auto')\n",
        "\n",
        "# EarlyStopping \n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=1,\n",
        "                                                   restore_best_weights=True)    # loss 증가 시 종료\n",
        "\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "hist = model.fit(dataset,\n",
        "          validation_data=val_dataset,\n",
        "          epochs=EPOCH,\n",
        "          callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381f6494-5141-48c9-908e-941f39c215e6",
        "id": "BRLmn1c8fCPN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 3.4957\n",
            "Epoch 1: val_loss improved from inf to 3.12609, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 52s 100ms/step - loss: 3.4957 - val_loss: 3.1261\n",
            "Epoch 2/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 3.0198\n",
            "Epoch 2: val_loss improved from 3.12609 to 2.95559, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 3.0198 - val_loss: 2.9556\n",
            "Epoch 3/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.8598\n",
            "Epoch 3: val_loss improved from 2.95559 to 2.84718, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.8598 - val_loss: 2.8472\n",
            "Epoch 4/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.7383\n",
            "Epoch 4: val_loss improved from 2.84718 to 2.76984, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.7383 - val_loss: 2.7698\n",
            "Epoch 5/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.6378\n",
            "Epoch 5: val_loss improved from 2.76984 to 2.70724, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.6378 - val_loss: 2.7072\n",
            "Epoch 6/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.5465\n",
            "Epoch 6: val_loss improved from 2.70724 to 2.66097, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.5465 - val_loss: 2.6610\n",
            "Epoch 7/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.4621\n",
            "Epoch 7: val_loss improved from 2.66097 to 2.62056, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.4621 - val_loss: 2.6206\n",
            "Epoch 8/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.3830\n",
            "Epoch 8: val_loss improved from 2.62056 to 2.58517, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.3830 - val_loss: 2.5852\n",
            "Epoch 9/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.3086\n",
            "Epoch 9: val_loss improved from 2.58517 to 2.55379, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.3086 - val_loss: 2.5538\n",
            "Epoch 10/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.2379\n",
            "Epoch 10: val_loss improved from 2.55379 to 2.52570, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.2379 - val_loss: 2.5257\n",
            "Epoch 11/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.1698\n",
            "Epoch 11: val_loss improved from 2.52570 to 2.50364, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.1698 - val_loss: 2.5036\n",
            "Epoch 12/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.1050\n",
            "Epoch 12: val_loss improved from 2.50364 to 2.48241, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.1050 - val_loss: 2.4824\n",
            "Epoch 13/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.0429\n",
            "Epoch 13: val_loss improved from 2.48241 to 2.46734, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 2.0429 - val_loss: 2.4673\n",
            "Epoch 14/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.9831\n",
            "Epoch 14: val_loss improved from 2.46734 to 2.45595, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.9831 - val_loss: 2.4560\n",
            "Epoch 15/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.9258\n",
            "Epoch 15: val_loss improved from 2.45595 to 2.44204, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.9258 - val_loss: 2.4420\n",
            "Epoch 16/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.8708\n",
            "Epoch 16: val_loss improved from 2.44204 to 2.43743, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.8708 - val_loss: 2.4374\n",
            "Epoch 17/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.8175\n",
            "Epoch 17: val_loss improved from 2.43743 to 2.42631, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.8175 - val_loss: 2.4263\n",
            "Epoch 18/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.7655\n",
            "Epoch 18: val_loss improved from 2.42631 to 2.42100, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.7655 - val_loss: 2.4210\n",
            "Epoch 19/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.7162\n",
            "Epoch 19: val_loss did not improve from 2.42100\n",
            "487/487 [==============================] - 48s 98ms/step - loss: 1.7162 - val_loss: 2.4222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "Epoch 18에서 val_loss 값이 2.42으로 가장 낮았다가 다음 번에 증가함을 알 수 있다. 아직 목표 손실값(2.2 이하)에는 미치지 못한다.\n",
        "\n",
        "그래프로 확인해보면 다음과 같다.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "OGgBud5jh2-O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "3f4629dc-f3fb-4ddf-a213-e3fd568d2888",
        "id": "ZgE8MzLqfRSG"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs_range = range(19)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Cross Entropy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XsPDXKND-tp"
      },
      "source": [
        "<br><br>\n",
        "\n",
        "**[문장 생성]**\n",
        "\n",
        "generate_text 함수를 만들어, Model에게 시작 문장을 전달하면 Model이 이를 바탕으로 작문을 진행하게 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3vjDBJzDWO9"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=50):\n",
        "    # init_sentence도 텐서로 변환\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "**[생성된 문장]**\n",
        "\n",
        "Baseline Model을 통해 생성해 낸 문장은 다음과 같다. 아직 덜 완성된 듯한 문장도 보인다."
      ],
      "metadata": {
        "id": "0vlW5anminwn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ueUgXY1DclC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ca41fdfb-8e7c-410a-a394-e11e23feedb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> he s a monster <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m15h01YMI5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3fd9e9ad-45b5-469b-e871-c9b8065691e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> life is a gamble better make a fuss <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> life\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VbWGyZKv5hY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4fd1186e-9b12-450a-ee36-87f891635cdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> what a victorious thrill <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> what a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weM9akmMO8ZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a97706f6-7464-4ca2-a83a-c0ef3ff0e247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> we are in a world , <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> we are in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D93wMd9xGw-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d03344b-b65a-4330-af25-faedefb1bd4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> mind is when i see you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> mind is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5Eu-pZs2LjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "567d0032-faeb-49d4-98e8-62983dbc225e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> money is on my mind <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> money is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wHkHrYI2XTn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "66a75edf-97ab-44d1-d879-15e36bbf37e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> first i know i m a <unk> <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr67FO4t20HD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "477a6a9b-fd7a-4378-a69c-3ba9db0105db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> the most important thing is <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> The most important thing is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "###**2) Hyper parameter 조정**\n",
        "\n",
        "<br>\n",
        "\n",
        "Baseline을 토대로 Hyper parameter를 조정하고, 이에 따른 Validation loss를 확인하였다. 수치를 변화시킴에 따라 훈련을 시키는 형태와 사이즈가 달라지며, 이로 인해 loss값이 달라짐을 알 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "**[ Hyper parameter 조정 및 결과 ]**"
      ],
      "metadata": {
        "id": "bmc7vWHJdhED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| - | BATCH SIZE | EMBEDDING SIZE | HIDDEN SIZE | VALIDATION LOSS | BEST POINT | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|256|256| 1024 |**2.42**| epoch 18 | Baseline |\n",
        "|2차|256|2048| 1024 |**2.29**| epoch 9 | - |\n",
        "|3차|256|256| 2048 |**2.26**| epoch 15 | - |\n",
        "|**4차**|**256**|**2048**| **2048** |**2.10**| **epoch 7** |  **✓ loss 2.2 이하 달성** |\n",
        "|5차|128|256| 1024 |**2.44**| epoch 14 | Batch size 상관성 확인(1차 기준 Emb, Hidd 통제) |\n",
        "|6차|512|256| 1024 |**2.41**| epoch 28 | Batch size 상관성 확인(1차 기준 Emb, Hidd 통제) |\n"
      ],
      "metadata": {
        "id": "nGJZcAZ1Nbqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "validation loss를 기준으로, 4차 시도의 설정(batch size=256 , embedding size=2048 , hidden size=2048)을 적용했을 때 결과가 가장 양호했다. epoch 7 일 때 loss 2.10을 기록했다.\n",
        "\n",
        "LMS에서 요구한 기본조건과 다른 설정(최대 토큰길이 등)으로 16회 가량 추가 테스트한 결과를 포함하여 고려하였을 때, EMBEDDING SIZE 및 HIDDEN SIZE가 증가함에 따라 대체적으로 loss가 낮아짐을 알 수 있었다.(음의 상관관계)\n",
        "\n",
        "또한, BATCH SIZE도 loss값과 관련이 있는지 알아보기 위해 128, 256, 512로 값을 달리해가며 테스트하였으나 loss은 크게 달라지지 않았다. \n",
        "\n",
        "\n",
        "다음은 **loss 최소치(2.10)**를 보인 **4차 테스트**에 대한 내용이다."
      ],
      "metadata": {
        "id": "FeSbspssrxtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True,\n",
        "    reduction='none'\n",
        ")\n",
        "\n",
        "EPOCH = 300\n",
        "\n",
        "# ModelCheckpoint\n",
        "filename = 'best_epoch{}_batch{}.h5'.format(EPOCH, BATCH_SIZE)\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(filename,\n",
        "                                                   monitor='val_loss',\n",
        "                                                   verbose=1,\n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_best_only=True,\n",
        "                                                   mode='auto')\n",
        "\n",
        "# EarlyStopping \n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=1,\n",
        "                                                   restore_best_weights=True)    # 증가 1번까지만 참고 끝내는 걸로 변경\n",
        "\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "hist = model.fit(dataset,\n",
        "          validation_data=val_dataset,\n",
        "          epochs=EPOCH,\n",
        "          callbacks=[checkpoint_cb, early_stopping_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bca23d9-05c6-454f-8da0-357737eaaa66",
        "id": "5SPF8nk2nIol"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 3.1506\n",
            "Epoch 1: val_loss improved from inf to 2.80135, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 149s 298ms/step - loss: 3.1506 - val_loss: 2.8013\n",
            "Epoch 2/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.6181\n",
            "Epoch 2: val_loss improved from 2.80135 to 2.54780, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 2.6181 - val_loss: 2.5478\n",
            "Epoch 3/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 2.2740\n",
            "Epoch 3: val_loss improved from 2.54780 to 2.37036, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 2.2740 - val_loss: 2.3704\n",
            "Epoch 4/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.9401\n",
            "Epoch 4: val_loss improved from 2.37036 to 2.23908, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 1.9401 - val_loss: 2.2391\n",
            "Epoch 5/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.6339\n",
            "Epoch 5: val_loss improved from 2.23908 to 2.15260, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 1.6339 - val_loss: 2.1526\n",
            "Epoch 6/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.3795\n",
            "Epoch 6: val_loss improved from 2.15260 to 2.10881, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 1.3795 - val_loss: 2.1088\n",
            "Epoch 7/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.1899\n",
            "Epoch 7: val_loss improved from 2.10881 to 2.10213, saving model to best_epoch300_batch256.h5\n",
            "487/487 [==============================] - 144s 295ms/step - loss: 1.1899 - val_loss: 2.1021\n",
            "Epoch 8/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 1.0678\n",
            "Epoch 8: val_loss did not improve from 2.10213\n",
            "487/487 [==============================] - 144s 294ms/step - loss: 1.0678 - val_loss: 2.1197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "34003719-98d8-46a6-c221-13c68e9c12d2",
        "id": "Kk7704bgnIoz"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "epochs_range = range(8)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Cross Entropy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "**[생성된 문장]**\n",
        "\n",
        "Baseline Model을 통해 생성해 낸 문장에 비해 완성도가 있다. 또한 제법 긴 문장(first you get her name , then you get her number)도 만들어냈다."
      ],
      "metadata": {
        "id": "goL5OrEdnU6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "da38eed0-da3c-473d-88e8-c3a7d7a76575",
        "id": "QanfCjtKnbzj"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> he s the only one for me <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "736dd764-6bf9-48f1-fc8e-79e0bdf313fb",
        "id": "cxfy1ktdnbzk"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> life s too short to not go for broke <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> life\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "533d1046-1179-4e92-c934-b2388232d082",
        "id": "AIcCJXSjnbzk"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> what a girl is to do ? <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> what a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "620926e8-aa49-4ee2-8edb-6e608c65c895",
        "id": "-uXLaTQYnbzl"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> we are in the moment <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> we are in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1bc8e404-8236-40b2-9c9a-bf09f1bc4acd",
        "id": "haeoqtxQnbzl"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> mind is like a compass <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> mind is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "657e58fd-5c0b-4e6a-d929-acf12c49c199",
        "id": "Bv60Hubenbzm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> money is the motivation <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> money is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "893b398e-bcb2-41ae-fc16-8792c61594b4",
        "id": "4C2lckXdnbzm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> first you get her name , then you get her number <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d48141bd-badb-4522-c2fb-bc131b6c5b64",
        "id": "-5topWTXnbzm"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> the most important thing is real <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> The most important thing is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "###**3) Vocabulary 확대**\n",
        "\n",
        "<br>\n",
        "\n",
        "앞서 토큰을 생성하는 과정에서 num_words = 12000을 설정했다. 12000 단어만 기억할 수 있는 tokenizer를 만들고, 여기 포함되지 않는 단어는 \\<unk>으로 바꾸었다.\n",
        "\n",
        "인수를 바꿔가며 테스트를 하는 과정에서 \\<unk>이 쓰인 불완전한 문장도 여러번 발견되었다. \n",
        "\n",
        "*   money is a \\<unk>\n",
        "*   mind is a \\<unk>\n",
        "*   first i know i m a \\<unk>\n",
        "\n",
        "<br>\n",
        "\n",
        "이런 문제를 해결하고, 보다 풍성한 표현의 작사를 할 수 있기를 기대하며 tokenizer의 num_words 설정을 달리해보았다. \n",
        "\n",
        "**단어수를 각각 16000개, 20000개로 증가**시켰다. 정확한 비교를 위해 다른 인수들은 loss 최저값을 기록한 4회차와 동일하게 설정한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "다음은 Vocabulary 조정의 결과이다.\n",
        "\n",
        "2회의 시도 모두 validation loss가 2.2 이하로 낮은 수치를 기록했다. 기본적으로 안정적인 문장을 생성했음을 알 수 있다.\n",
        "\n",
        "<br>\n",
        "\n",
        "**[ Vocabulary 조정 및 결과 ]**"
      ],
      "metadata": {
        "id": "T0iZEfJkdhVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| - | VOCABULARY | BATCH SIZE | EMBEDDING SIZE | HIDDEN SIZE | VALIDATION LOSS | BEST POINT | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|7차| **16000 words** |256|2048| 2048 |**2.15**| epoch 7 | |\n",
        "|8차| **20000 words** |256|2048| 2048 |**2.17**| epoch 7 |  |"
      ],
      "metadata": {
        "id": "EoQA5K7iuCMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "**⎮ 16000 words**"
      ],
      "metadata": {
        "id": "Ye1YsQcIt98e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0f8734d8-6c94-436e-9ae0-9f635f76b49e",
        "id": "QgZuvJZP2rye"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> he s a monster <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "50452607-0ef0-4722-b86b-30089a8a77ef",
        "id": "VqPwaKuY2ryu"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> life s trades . <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> life\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c1169b48-2d74-4464-b1de-62593e22693c",
        "id": "XH591LTc2ryv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> what a lovely walk we ve taken ! <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> what a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "30df3e01-66a3-4786-a7f3-a19bde50a8ba",
        "id": "hg_LTN-S2ryv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> we are in the same key <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> we are in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8c8711bc-9bbe-486e-d36d-8c59268c950a",
        "id": "uDfM-8zy2ryv"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> mind is waiting <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> mind is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d19debb5-b683-4ec7-aff5-357545a41fa8",
        "id": "b7MMY5it2ryw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> money is the motivation <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> money is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8bdbe958-0930-4f67-89da-097781a434c4",
        "id": "nPoNL36I2ryw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> first i mma scorch her , then i mma torch her <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d865065d-48be-4cd5-ded0-2f23518edcdb",
        "id": "agU4toDb2ryw"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> the most important thing is the year <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> The most important thing is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "**⎮ 20000 words**"
      ],
      "metadata": {
        "id": "Ivohddnv2P8N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aa1e8ce6-aca9-4338-ce39-939df2d28b5a",
        "id": "nWDSvMUU7EXa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> he s a highway chile <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0bb7c09d-6371-421a-bb66-7f55a84646c6",
        "id": "IzY82f287EXo"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> life is a marathon <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> life\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9bed9221-a949-474b-ad7f-6c8a66474a01",
        "id": "U9tXz_w_7EXo"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> what a lovely walk we ve taken ! <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> what a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "160fc2eb-b88f-4edf-f5d0-bb5e2ffce085",
        "id": "RidhDNfM7EXo"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> we are in the lab , we re not in the zone <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> we are in\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b0508a78-c7ad-442e-a085-e1d4e359069e",
        "id": "elfb1xqS7EXp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> mind is a dialogue between <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> mind is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ac35992d-0c79-4b93-e1a4-d699fedc2587",
        "id": "PcavTHeW7EXp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> money is the motivation <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> money is\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "235bca8a-f137-499f-dff7-2a72a6e2923e",
        "id": "gw3EBVlW7EXp"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> first you re up , then you re down and in between <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> first\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "15b86992-68c2-468b-f711-428c446ee851",
        "id": "laq8jHr_7EXq"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> the most important thing is making music and it s all <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> The most important thing is\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br><br>\n",
        "\n",
        "###**4) 소 결** \n",
        "\n",
        "<br><br>\n",
        "\n",
        "**[ 문장 생성에서의 손실값(loss)에 대한 고찰 ]**\n",
        "\n",
        "새롭게 만들어 낸 문장의 손실값(loss)을 구한다는 게 무슨 의미일까. 처음에는 수행목적과 전혀 일치하지 않는 평가방식이라고 생각했다. 전에 없던 문장을 창조해 냈는데 무엇과 비교를 해서 손실값을 구한다는 건가. 그게 무슨 의미가 있지? \n",
        "\n",
        "그러나 model의 구현방식을 자세히 들여다보고 나서야 이번 Exploration에서의 loss가 뜻하는 바를 이해하게 되었다.\n",
        "\n",
        "<br>\n",
        "\n",
        "src_input = tensor[:, :-1]  \n",
        "tgt_input = tensor[:, 1:]\n",
        "\n",
        "source문장과 target문장을 생성하는 위의 과정을 통해서 같은 문장 내의 뒷 단어를 label로 갖게 된다. 문장의 제일 마지막 단어는 label이 없다. 결국 정답이 있는 문제에 대해 최대의 확률값을 구하는 방식으로 다음에 올 단어를 유추하는 process가 구현된다.\n",
        "\n",
        "우리가 generate_text Function을 통해 새로운 단어 또는 구(句)를 입력하여 문장을 생성해내는 과정 역시 이러한 방식에 기반하여 이루어진다. Entropy를 최소화하기 위한 다음 단어를 선택하게 되고, 선택을 올바르게 할수록 그 이후의 선택의 폭은 줄어든다. \n",
        "\n",
        "그렇다면 이번 Exploration에서 loss를 줄여나간다는 것은 문맥이나 용법 상 적정한 답을 찾아나간다는 의미도 있겠지만, 결국 제일 평범한 답을 찾는다는 의미가 될 수도 있겠다. 그런 관점에서 **loss를 목표로 삼는 것은 '작사'라는 영역을 평가하기에 온전한 지표는 아닐 수도 있겠다**는 생각이 들었다.\n",
        "\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "i-9htxKBAg68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br><br>"
      ],
      "metadata": {
        "id": "kF2xTT9P7KQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##**2. 시적표현 선별; 정성적 평가**"
      ],
      "metadata": {
        "id": "yuvypF8iw3Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "###**1) 회차별 문장력 비교**\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "57rdowCDw3N0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그렇다면 다양한 인자 조정에 따른 loss값의 비교는 잠시 내려놓고, 각각의 문장력이 어떤지 살펴보자. 회차별로 모델이 생성해 낸 문장을 입력한 첫 단어(init_sentence)끼리 묶어서 살펴보고, 퀄리티를 비교했다.\n",
        "\n",
        "문장력은 정성적으로 평가한다.(=내 마음이 움직이는 걸 뽑았다.)\n",
        "\n",
        "<br>\n",
        "\n",
        "**⎮ \\<start> he** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |he **s a monster**| ★☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |he **s a monster**|★☆☆☆☆| - |\n",
        "|3차|| 2.26 |he **s a monster**|★☆☆☆☆| - |\n",
        "|4차|| 2.10 |he **s the only one for me** |★☆☆☆☆| - |\n",
        "|5차|| 2.44 |he **s a monster**|★☆☆☆☆| - |\n",
        "|6차|| 2.41 |he **s a monster**|★☆☆☆☆| - |\n",
        "|7차|| 2.15 |he **s a monster**|★☆☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |he **s a highway chile**|★★★☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "N0oH-l3ELqFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> life** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |life **is a gamble better make a fuss**| ★★☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |life **is worth living , so don t be alarmed**|★★★☆☆| - |\n",
        "|3차|| 2.26 |life **is worth living again relationship on a ski slope**|★★★☆☆| - |\n",
        "|4차|| 2.10 |life **s too short to not go for broke**|★★★★☆| - |\n",
        "|5차|| 2.44 |life **is a marathon**|★☆☆☆☆| - |\n",
        "|6차|| 2.41 |life **is a gamble , a long time ago**|★★☆☆☆| - |\n",
        "|7차|| 2.15 |life **s trades**|★☆☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |life **is a marathon**|★☆☆☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "8yYNjl1lAKSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> what a** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |what a **victorious thrill**| ★☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |what a **little bitty ?**|★☆☆☆☆| - |\n",
        "|3차|| 2.26 |what a **girl is to do ?**|★☆☆☆☆| - |\n",
        "|4차|| 2.10 |what a **girl is to do ?**|★☆☆☆☆| - |\n",
        "|5차|| 2.44 |what a **victorious thrill**|★★☆☆☆| - |\n",
        "|6차|| 2.41 |what a **lovely phrase i am a god**|★★☆☆☆| - |\n",
        "|7차|| 2.15 |what a **lovely walk we ve taken !**|★☆☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |what a **lovely walk we ve taken !**|★☆☆☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "UiXZnd2oAbDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> we are in** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |we are in **a world**| ★☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |we are in **the dark**|★★☆☆☆| - |\n",
        "|3차|| 2.26 |we are in **the zone , damn near got my eyes closed**|★★★☆☆| - |\n",
        "|4차|| 2.10 |we are in **the moment**|★★☆☆☆| - |\n",
        "|5차|| 2.44 |we are in **the dark**|★★☆☆☆| - |\n",
        "|6차|| 2.41 |we are in **the right**|★★☆☆☆| - |\n",
        "|7차|| 2.15 |we are in **the same key**| ★★☆☆☆ |16000 words|\n",
        "|8차|| 2.17 |we are in **the lab , we re not in the zone**|★★★★☆| 20000 words |"
      ],
      "metadata": {
        "id": "BRqgrFkqAoBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> mind is** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 | mind is **when i see you**| ★☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |mind is **like a compass**|★☆☆☆☆| - |\n",
        "|3차|| 2.26 |mind is **like a compass**|★☆☆☆☆| - |\n",
        "|4차|| 2.10 |mind is **like a compass**|★☆☆☆☆| - |\n",
        "|5차|| 2.44 |mind is **all i need**|★☆☆☆☆| - |\n",
        "|6차|| 2.41 |mind is **a holiday**|★★★☆☆| - |\n",
        "|7차|| 2.15 |mind is **waiting**|★★★☆☆| 16000 words |\n",
        "|8차|| 2.17 |mind is **a dialogue between**|★★★★☆| 20000 words |"
      ],
      "metadata": {
        "id": "1JdbWLNJAoN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> money is** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |money is **on my mind**| ★☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |money is **a shame i m a fool now you re mine**|★★★☆☆| - |\n",
        "|3차|| 2.26 |money is **the motivation**|★☆☆☆☆| - |\n",
        "|4차|| 2.10 |money is **the motivation**|★☆☆☆☆| - |\n",
        "|5차|| 2.44 |money is **the motivation**|★☆☆☆☆| - |\n",
        "|6차|| 2.41 |money is **the motivation**|★☆☆☆☆| - |\n",
        "|7차|| 2.15 |money is **the motivation**|★☆☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |money is **the motivation**|★☆☆☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "0mA3nBzNAoX0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> first** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |first **i know i m a \\<unk>**| ☆☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |first **you get her name , then you get her number**|★★☆☆☆| - |\n",
        "|3차|| 2.26 |first **i spin around and vomit then i shit up on it**|★☆☆☆☆| - |\n",
        "|4차|| 2.10 |first **you get her name , then you get her number**|★★☆☆☆| - |\n",
        "|5차|| 2.44 |first **i mma scorch her , then i mma torch her**|★★★★☆| - |\n",
        "|6차|| 2.41 |first **i mma scorch her , then i mma torch her**|★★★★☆| - |\n",
        "|7차|| 2.15 |first **i know i m a motherfucking monster**|★★☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |first **you re up , then you re down and in between**|★★☆☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "B3vmb4zYAoi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "**⎮ \\<start> The most important thing is** ㅡ \n",
        "\n",
        "<br>\n",
        "\n",
        "| - ||LOSS| --------------------------------------------- SENTENCE --------------------------------------------- | QUALITY | note |\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
        "|1차|| 2.42 |The most important thing is **-**| ☆☆☆☆☆ | Baseline |\n",
        "|2차|| 2.29 |the most important thing is **real**|★☆☆☆☆| - |\n",
        "|3차|| 2.26 |the most important thing is **ever promised tomorrow**|★★★☆☆| - |\n",
        "|4차|| 2.10 |the most important thing is **real**|★☆☆☆☆| - |\n",
        "|5차|| 2.44 |the most important thing is **\\<unk>**|☆☆☆☆☆| - |\n",
        "|6차|| 2.41 |the most important thing is **the year**|★☆☆☆☆| - |\n",
        "|7차|| 2.15 |the most important thing is **-**|☆☆☆☆☆| 16000 words |\n",
        "|8차|| 2.17 |the most important thing is **making music and it s all**|★★★☆☆| 20000 words |"
      ],
      "metadata": {
        "id": "tXawrEqdBfFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br><br>\n",
        "\n",
        "###**2) 소 결**\n",
        "\n",
        "<br>\n",
        "\n",
        "loss값이 상대적으로 높더라도 비유적인 측면이나 창의성에서 한 번 더 생각하게 만드는 문장들이 있었다. 반면 loss값이 낮아서 더 좋은 결과물이라고 판단할만 하지만 사실상 진부한 표현도 있었다.\n",
        "\n",
        "전반적으로 더 많은 단어를 포함한 tokenizer를 적용했을 때의 표현이 더 새롭고 풍성하다고 느껴졌으나, 일반화할 정도의 차이는 아니라고 판단된다. \n",
        "\n",
        "7차 시도는 loss가 2.15로 우수한 성능을 보인 경우이나, 'the most important thing is'의 입력값을 그대로 출력해냈다. \\<end>로 바로 끝내버리는 게 확률적으로 유리했을지 모르지만 가사를 만들어내는 역할로서는 의미가 없다.\n",
        "\n",
        "오히려 살짝 비문처럼 느껴지기도 하지만 그런 측면에서 오히려 예술성이 느껴지는 문장들은 이번 과정에서 loss를 성능의 지표로 삼는 것이 완벽하지 않음을 시사한다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "사실 가장 오랜시간 결과창을 들여다 보게 만들었던 문장은 가중치 설정 등의 측면에서 유효하지 않다고 판단하여 결과에서는 제외했던 테스트 가운데 있었다.\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "ZlVRWp-wczOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> he\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "742740ad-8a5f-4cee-8cb7-7b16314ba8d5",
        "id": "zBpxOWsSwHlH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> he s a walker in the rain <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> life\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "249f7687-2e6f-4ef7-81b8-d0dc4f2d0c83",
        "id": "0kHexhZiwHlT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> life is a roller coaster but still unfair <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-\n",
        "\n",
        "<br><br><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "_RwKEC6inZkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##**3. Case study**"
      ],
      "metadata": {
        "id": "AhAa2VR9wvl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "###**1) KoGPT2**\n",
        "\n",
        "<br>\n",
        "\n",
        "작사 관련 Exploration을 하면서 AI기반의 문장 생성에 관심이 생겼다. SKT에서 우리말을 기반으로 만든 Generative Pre-trained Transformer(GPT)을 경험해보자. \n",
        "\n",
        "GPT-2는 머신러닝 알고리즘을 활용해 입력된 샘플 텍스트를 구문론적, 문법적, 정보 등의 일관성을 갖춘 텍스트로 생성하는 자연어 처리 모델이다. 한국어로 학습된 오픈소스 기반 GPT-2 모델인 KoGPT-2는 질문에 대한 응답 생성, 문장 완성, 챗봇 등 한국어 해석이 필요한 여러 애플리케이션의 머신러닝 성능을 향상할 수 있다고 한다.\n",
        "\n",
        "챗봇 구축, 텍스트 감성 예측, 텍스트 분석 기반 응답 생성에 사용될 수 있으며, 관심 있는 개발자는 모델과 관련 소스를 다운로드해 프로젝트에 적용하거나 수정하면 된다[4]ㅡ고 나와있다.\n",
        "\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "nK9oyBNMwvl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1JSKLhIo3Xt",
        "outputId": "2192ec1d-44ad-4695-b238-62c73c44bbc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n",
        "bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "pad_token='<pad>', mask_token='<mask>')\n",
        "tokenizer.tokenize(\"이건 저도 처음 시도해보네요. 그럼우리 모두다 화이팅 아이펠🤗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "fb02e277f578443f9b4cdcde2467de1b",
            "80c9536622dc4aee984b2a7f782271a7",
            "a2c8d2942087483ca7e3c7a3d1e4e340",
            "599109db0bdc41bbaae950af7f6aa2d4",
            "17ebd0db5c6a4f62936d914eabd69d1e",
            "5dc9bd6f72f74027ab6e2c8cb3ef2a35",
            "e42857c0a5ed43f7b348e4dd1882585b",
            "e0bd2d91915948c99ec748968593e954",
            "50f9330fdf5f456cb0316bea0fafd07c",
            "a89d325953844909a224b0ac8e050ad8",
            "b976a55f41bd4868b5bbfccd3d0e1009",
            "9fe1678ccb1f46259cf5696b3ea7a5ff",
            "012aa6a655f649f2ac4489c7f7453303",
            "32f3b6afd2384f8a914e353e9052c2bf",
            "61c15064317141b4942448b40cd876d4",
            "27cce30a7a2d45839d5c367f0330f6ce",
            "3296807401ee4a1d9b235b691b2c5ab0",
            "be2e319749d946a78537022987a822af",
            "0a29ffa1c3b74215b18e55b353b22cfc",
            "eab8d1df3fb643ea9f8918240e62cba3",
            "89aac0e1749143f99d6c697c05c6ce77",
            "fe4434d9ae614438a2399a9656dfafb0"
          ]
        },
        "outputId": "a83b5efa-c279-4820-e8a1-efd45fab2389",
        "id": "spVeJMqsIi9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb02e277f578443f9b4cdcde2467de1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/0.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fe1678ccb1f46259cf5696b3ea7a5ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁이건',\n",
              " '▁저',\n",
              " '도',\n",
              " '▁처음',\n",
              " '▁시도',\n",
              " '해보',\n",
              " '네',\n",
              " '요.',\n",
              " '▁그럼',\n",
              " '우리',\n",
              " '▁모두',\n",
              " '다',\n",
              " '▁화',\n",
              " '이팅',\n",
              " '▁아이',\n",
              " '펠',\n",
              " '🤗']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '인공지능'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=50,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae2a0e37-6fac-4aa3-e390-847e6fcfa689",
        "id": "8t6a0bmyLOZm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능(AI) 기반의 스마트시티를 구축하는 데 주력할 계획이다.\n",
            "이를 위해 올해부터 2022년까지 총 1조원을 투입한다.\n",
            "이번 사업은 △스마트도시 조성 및 운영체계 고도화 사업(총사업비 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '사랑한다는 말은'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=50,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "769c52b8-1527-479a-886e-9137b4228b8a",
        "id": "kNPUmsMNLo8m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사랑한다는 말은, 그 자체가 하나의 '상징'일 수 있다.\n",
            "그것은 바로 이 상상의 세계를 구성하는 것이다.\n",
            "이러한 상상 세계는 어떤 특정한 대상을 향해 열려 있는 것이 아니라, 다른 대상과 함께 존재하는 것이기 때문이다.\n",
            "따라서 우리는 이러한 상상력을 통해 우리가 경험\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '떴다. 떴다. 비행기 날아라. 날아라.'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=50,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f389b397-7f64-4b84-887b-368a260bfb24",
        "id": "ApsinGVIk4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "떴다. 떴다. 비행기 날아라. 날아라.\"\n",
            "\"그럼, 비행기를 타고 가자.\"\n",
            "비행기가 뜨자 나는 다시 한 번 하늘을 향해 외쳤다.\n",
            "하늘을 향한 나의 시선은 하늘 위로 치솟았다.\n",
            "나는 그제야 비로소 내 앞에 섰다.\n",
            "그리고\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '건강한 생활'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=50,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9858fd44-25ba-4ce8-f7b8-d9878318ab1c",
        "id": "GoF59iuPKLm9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "건강한 생활습관을 개선하는 것이 중요하다.\n",
            "특히, 스트레스를 많이 받는 사람은 피해야 한다.\n",
            "스트레스가 쌓이면 면역력이 떨어지기 때문에 평소보다 더 많은 양의 음식을 섭취하고, 충분한 수면을 취하는 것도 도움이 된다.\n",
            "또한 규칙적인 운동을 통해 스트레스의\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "text = '근력 운동을 할 때'\n",
        "input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "gen_ids = model.generate(input_ids,\n",
        "                           max_length=50,\n",
        "                           repetition_penalty=2.0,\n",
        "                           pad_token_id=tokenizer.pad_token_id,\n",
        "                           eos_token_id=tokenizer.eos_token_id,\n",
        "                           bos_token_id=tokenizer.bos_token_id,\n",
        "                           use_cache=True)\n",
        "generated = tokenizer.decode(gen_ids[0])\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204e451e-7e92-4e01-f69d-e58637944475",
        "id": "AcACKxurLxAn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "근력 운동을 할 때 가장 중요한 것은 바로 운동이다.\n",
            "운동할 때는 반드시 스트레칭을 해야 한다.\n",
            "스트레스는 체내 호르몬 분비를 촉진시켜 근육과 인대의 긴장을 풀어주고 혈액순환을 원활하게 해 준다.\n",
            "또한 스트레스를 해소하고 면역력을\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "전체적으로 구어체의 문장 보다는 문어체의 문장에 잘 맞는 것 같다. 노래가사와 같은 문구를 넣으면 주로 다음 줄에 대화체 형식의 문장이 이어져서 맥락이 깨지는 느낌을 받았다.\n",
        "\n",
        "내용이 연결되는 듯 하면서 아닌 것도 같고, 어디선가 단순히 긁어오는 듯한 느낌도 없지 않다. \n",
        "'건강한 생활'이라는 입력문과 '근련 운동을 할 때'라는 입력문을 넣었을 때 결과를 비교해 보면, 문장구조가 유사하면서도 겹치지 않아서 단순히 붙여넣는 건 아닌 것 같기도 하다. \n",
        "다만 \"근력 운동을 할 때 가장 중요한 것은 바로 운동이다.\"와 같이 의미상으로 중첩되는 문장을 생성하는 문제를 보였다.\n",
        "\n",
        "transformer 등에 관한 기본지식을 쌓은 이후에, GPT가 어떤 방식으로 구현되는지 자세히 알아보는 것도 도움이 되겠다. \n",
        "\n",
        "\n",
        "-\n",
        "\n",
        "<br><br><br><br><br><br>\n"
      ],
      "metadata": {
        "id": "JU74Ue5Xwvl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **III. 결 론**\n",
        "\n",
        "<br>\n",
        "\n",
        "* 해당 알고리즘도 결국 Lable이 있는 Classification의 일종이다.\n",
        "* 적정 embedding size, hidden size 등의 설정을 통해 validation loss를 조절할 수 있다.\n",
        "* tokenizer가 보유한 vocabulary의 양에 따라 validation loss를 조절할 수 있다.\n",
        "* 다만, validation loss가 낮다고해서 목적에 부합하는 문장생성을 보장하는 것은 아니다.\n",
        "* 문제의 성격에 따른 loss의 의미 이해가 요구되며, 필요 시 해당 문제에 부합하는 평가지표의 보완으로 효과적인 목적달성이 가능할 것으로 판단된다. \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "####**[ 맺음말 ]**\n",
        "\n",
        "\n",
        "이번 과정을 통해 구현해 낸 Model은 학습한 내용을 짜깁기하여 최대한 그럴 듯하게 유사한 문장을 생성해내는 것이겠지만, 입력으로 넣은 새로운 단어에 맞추어 문장을 만들어 주는 과정에서 마치 상호작용을 하는 듯한 느낌을 받았다. \n",
        "\n",
        "또한 생성한 문장이 내포하는 의미가 특정 성향이나 가치관과 결부된 경우를 보며, 기계에 의한 확률적 선택일 뿐 임에도 충분히 논란이 될 수 있겠다는 생각도 들었다. \n",
        "\n",
        "언어를 다루는 측면 때문일까. 이전 Exploration 과정들과는 확연히 구분되는 경험이었다. 주어진 데이터를 기반으로 AI가 만들어 낸 문장이 내포한 의미와 그 글귀를 보고 느끼는 감정은 어디에서 비롯되었다고 볼 것인가ㅡ하는 부질없는 물음이 남았다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1GyE3sDpSy4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "            \n",
        "<br><br><br>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "< 참고문헌 >\n",
        "\n",
        "- LMS, E-06, 작사가 인공지능 만들기 [1]\n",
        "- ⌈혼자 공부하는 머신러닝 딥러닝⌋, 한빛미디어, 박해선 지음 [2]\n",
        "- 밑바닥부터 시작하는 딥러닝2 [3]\n",
        "- https://github.com/SKT-AI/KoGPT2 [4]\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback\n",
        "\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VvtvwZRiR-eU"
      }
    }
  ]
}